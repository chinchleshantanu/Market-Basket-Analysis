{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Market Basket Analysis**\n",
        "\n",
        ">- <mark>**Market Basket Analysis (MBA)**</mark> is a used by businesses to understand the purchasing patterns of customers. It helps to identify the products that are frequently bought together in transactions.<br><br>\n",
        "- MBA works by generating association rules like \"If a customer buys bread, they are likely to also buy butter.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "souS8iS4mWxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eqhOwJ-F9v4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `numpy` and `pandas` are used for data manipulation and numerical computations.\n",
        "- `seaborn` and `matplotlib` are libraries for data visualization."
      ],
      "metadata": {
        "id": "9M-gauDAnmRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/Groceries_dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "exLWGgTmG4_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- This cell reads the dataset from a CSV file using pandas and loads it into the variable data.\n",
        "- The `data.head()` function shows the first 5 rows of the dataset to give a quick overview of the structure."
      ],
      "metadata": {
        "id": "YDr0wQMMpP8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "XC0FsaeOINFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `info()` is used to display a concise summary of the DataFrame (df). It provides important information about the structure of the dataset\n",
        "- `info()` is typically used early in the analysis to understand the dataset's structure and identify issues such as missing data or incorrect data types.\n",
        "- It also shows the memory usage of the DataFrame, which can be helpful for optimizing large datasets."
      ],
      "metadata": {
        "id": "kd2lAAs1pqou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "1ZFJBaQGIXYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `df.isnull()`: This function checks for missing (NaN) values in the DataFrame (df). It returns a new DataFrame of the same shape as df with True where the data is missing and False where it is not.\n",
        "\n",
        ">- `.sum()`: After identifying missing values, this function sums up the number of True values (i.e., the number of missing values) for each column. This gives you a count of how many missing values exist in each column.\n",
        "\n",
        ">- `.sort_values(ascending=False)`: This step sorts the resulting counts in descending order, so the columns with the most missing values appear at the top of the list."
      ],
      "metadata": {
        "id": "VzP2Ph-HqCUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['Date'], dayfirst=True)\n"
      ],
      "metadata": {
        "id": "qrmKGmcpIjtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `df.isnull()`: This function checks for missing (NaN) values in the DataFrame (df). It returns a new DataFrame of the same shape as df with True where the data is missing and False where it is not.\n",
        "- `.sum()`: After identifying missing values, this function sums up the number of True values (i.e., the number of missing values) for each column. This gives you a count of how many missing values exist in each column.\n",
        "- `.sort_values(ascending=False)`: This step sorts the resulting counts in descending order, so the columns with the most missing values appear at the top of the list."
      ],
      "metadata": {
        "id": "q9JmPm4HqROZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "B-jW1525JGvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "p8dQHM8NJLmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Item_distr=df.groupby(by='itemDescription').size().reset_index(name='Frequency').sort_values(by='Frequency', ascending=False).head(10)\n",
        "bars=Item_distr['itemDescription']\n",
        "height=Item_distr['Frequency']\n",
        "x_pos=np.arange(len(bars))\n",
        "\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.bar(x_pos, height, color=(0.2,0.3,0.5,0.5))\n",
        "plt.title(\"Top 10 sold item\")\n",
        "plt.xlabel('Item Names')\n",
        "plt.ylabel('No. of Quantity sold')\n",
        "plt.xticks(x_pos, bars)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-DHzUa3MJUqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**<mark>Grouping and Sorting Items by Frequency</mark>**\n",
        "\n",
        ">- `df.groupby(by='itemDescription')`: Groups the data by the itemDescription column (which represents different products).\n",
        "- `.size()`: Counts the number of occurrences (sales) for each item.\n",
        "- `.reset_index(name='Frequency')`: Resets the index and creates a new column called Frequency, which stores the count of how many times each item was sold.\n",
        "- `.sort_values(by='Frequency', ascending=False)`: Sorts the items in descending order based on how many times they were sold, with the most sold items at the top.\n",
        "- `.head(10)`: Selects the top 10 items with the highest sales.\n",
        "\n",
        "#**<mark>Prepare Data for Plotting</mark>**\n",
        "\n",
        ">- `bars`: Contains the names of the top 10 items that will be displayed on the x-axis of the bar chart.\n",
        "- `height`: Contains the corresponding frequency (number of times each item was sold) that will determine the height of each bar.\n",
        "- `x_pos`: Creates a sequence of positions (indices) corresponding to the number of items (top 10), used for the placement of the bars on the x-axis.\n",
        "\n",
        "#**<mark>Plotting the Bar Chart</mark>**\n",
        ">- `plt.figure(figsize=(16,9))`: Sets the figure size to 16 by 9 inches, which makes the plot large and easy to read.\n",
        "- `plt.bar(x_pos, height, color=(0.2,0.3,0.5,0.5))`: Creates a bar chart with the item positions (x_pos) on the x-axis and their sales (height) on the y-axis. The color argument defines the color and transparency of the bars.\n",
        "- `plt.title(\"Top 10 Sold Items\")`: Sets the title of the bar chart to \"Top 10 Sold Items\".\n",
        "- `plt.xlabel('Item Names')`: Labels the x-axis as \"Item Names\".\n",
        "- `plt.ylabel('No. of Quantity Sold')`: Labels the y-axis as \"No. of Quantity Sold\".\n",
        "- `plt.xticks(x_pos, bars)`: Assigns the item names (bars) as labels on the - - - `x-axis at the positions (x_pos)` corresponding to each bar.\n",
        "- `plt.show()`: Displays the bar chart.\n",
        "\n",
        "\n",
        "\n",
        "This plot visually highlights the 10 most frequently sold items, allowing you to quickly see which products are the most popular among customers.\n"
      ],
      "metadata": {
        "id": "ylZR8hjvqy_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_date= df.set_index(['Date'])\n",
        "df_date"
      ],
      "metadata": {
        "id": "AazI4oj6KsTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `df.set_index(['Date'])`: This command sets the Date column as the index of the DataFrame (df), which means that each row will now be indexed by the date on which the data was recorded or transaction occurred.\n",
        "- Having the Date as the index allows you to easily filter, sort, and analyze the data based on time, such as grouping by months, years, or performing rolling statistics."
      ],
      "metadata": {
        "id": "Mr7sbhnnsoIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_date = df.copy()\n",
        "df_date['Date'] = pd.to_datetime(df_date['Date'])\n",
        "df_date = df_date.set_index(['Date'])\n",
        "\n",
        "df_date.resample('M')['itemDescription'].count().plot(figsize=(20,8), grid=True, title= ' Number of item sold by month').set(xlabel='date', ylabel='no of item sold')"
      ],
      "metadata": {
        "id": "UQVj5KVjMWqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">-  `df.copy()`: This creates a copy of the original DataFrame (df) and assigns it to df_date. This is useful to avoid modifying the original DataFrame while performing operations that could change its structure.\n",
        "\n",
        ">- `pd.to_datetime(df_date['Date'])`: This function converts the Date column to a datetime format. This step is essential because it ensures that the date data is in a format that allows for time-based operations, such as resampling and plotting.\n",
        "\n",
        ">- `df_date.set_index(['Date'])`: This sets the Date column as the index of the DataFrame `(df_date)`. This action allows for easier time-series analysis, as all rows will now be indexed by their corresponding dates.\n",
        "\n",
        ">- `df_date.resample('M')`: This command groups the data into monthly intervals. The `M` stands for month, meaning that it will aggregate the data for each month in the DataFrame.\n",
        "- `['itemDescription'].count()`: This counts the number of entries (sales) for the `itemDescription` column in each month, giving the total number of items sold per month.\n",
        "`.plot(figsize=(20,8))`: This creates a line plot with a figure size of 20 by 8 inches, making it large and easy to read.\n",
        "- `grid=True`: This adds a grid to the plot for better visibility and readability of the data points.\n",
        "- `title='Number of Items Sold by Month'`: This sets the title of the plot to `\"Number of Items Sold by Month.\"`\n",
        "- `.set(xlabel='Date', ylabel='No. of Items Sold')`: This function sets the labels for the x-axis and y-axis to `\"Date\"` and `\"No. of Items Sold,\"` respectively."
      ],
      "metadata": {
        "id": "agBhI0odtgyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cust_level=df[['Member_number','itemDescription']].sort_values(by='Member_number',ascending=False)\n",
        "cust_level['itemDescription']=cust_level['itemDescription'].str.strip()\n",
        "cust_level"
      ],
      "metadata": {
        "id": "3WBWkHm1NjSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `df[['Member_number', 'itemDescription']]`: This selects only the `Member_number` and `itemDescription` columns from the original DataFrame (df). This new DataFrame (`cust_level`) will focus solely on these two pieces of information, which is important for analyzing customer purchase behavior.\n",
        "- `.sort_values(by='Member_number', ascending=False)`: This sorts the new DataFrame in descending order based on the `Member_number` column. Sorting by `Member_number` is useful for identifying the highest or most active customers first.\n",
        "\n",
        ">- `.str.strip()`: This method removes any leading or trailing whitespace from the itemDescription strings. This is important for ensuring that item names are clean and free from unnecessary spaces, which can cause issues in data analysis, such as duplicate entries."
      ],
      "metadata": {
        "id": "XEIz2_sQvoiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = [a[1]['itemDescription'].tolist() for a in list(cust_level.groupby(['Member_number']))]"
      ],
      "metadata": {
        "id": "NSW9l7FvORNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `cust_level.groupby(['Member_number'])`: This command groups the `cust_level` DataFrame by the `Member_number` column. Each group corresponds to a unique member, and all their associated item purchases are gathered together.\n",
        "- `list(...)`: Converts the grouped object into a list of tuples. Each tuple contains a `Member_number` and the corresponding DataFrame for that member.\n",
        "- `for a in ...`: This begins a loop that iterates over each tuple in the list. Here, a represents each tuple, where `a[0]` is the `Member_number` and `a[1]` is the DataFrame containing that member's purchases.\n",
        "- `a[1]['itemDescription']`: This accesses the itemDescription column of the DataFrame corresponding to the current `Member_number`.\n",
        "- `.tolist()`: Converts the `itemDescription` column into a standard Python list, containing all the item descriptions associated with that member.\n",
        "- `transactions = [...]`: This list comprehension collects the lists of item descriptions for all members into a single list called `transactions`. Each element in this list corresponds to the purchases made by one member, resulting in a nested list structure."
      ],
      "metadata": {
        "id": "vxsqd6m0w3eR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apyori"
      ],
      "metadata": {
        "id": "W-_SgRDlQC_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from apyori import apriori\n",
        "rules= apriori(transactions=transactions, min_support=0.002,min_confidence=0.05,min_lift=3,min_length=2)"
      ],
      "metadata": {
        "id": "VUsRwrnYO4hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- The `Apriori` algorithm identifies frequent itemsets in transactional data and derives association rules from them.\n",
        "\n",
        ">- `transactions=transactions`: This argument passes the previously created list of transactions (lists of items purchased by each customer) to the `Apriori` algorithm.\n",
        "- `min_support=0.002`: Requires an itemset to appear in at least 0.2% of transactions to be considered frequent.\n",
        "- `min_confidence=0.05`: Ensures that if an antecedent occurs, the consequent must also occur at least 5% of the time.\n",
        "- `min_lift=3`: Indicates the consequent is three times more likely to occur with the antecedent than without it.\n",
        "- `min_length=2`: Only considers itemsets that contain at least two items"
      ],
      "metadata": {
        "id": "jKXy-6EkyAps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=list(rules)"
      ],
      "metadata": {
        "id": "hxxwaT-FPTMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `results = list(rules)`: This line converts the association rules generated by the Apriori algorithm into a standard Python list."
      ],
      "metadata": {
        "id": "vBjB6EPlyzFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "LTZMfVTQQTpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect(results):\n",
        "    lhs = [tuple(result[2][0][0])[0] for result in results]\n",
        "    rhs = [tuple(result[2][0][1])[0] for result in results]\n",
        "    supports = [result[1] for result in results]\n",
        "    confidences = [result[2][0][2] for result in results]\n",
        "    lifts = [result[2][0][3] for result in results]\n",
        "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
        "\n",
        "resultsinDataFrame = pd.DataFrame(inspect(results), columns=['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])\n",
        "\n",
        "resultsinDataFrame['Lift'] = pd.to_numeric(resultsinDataFrame['Lift'])\n",
        "\n",
        "resultsinDataFrame.nlargest(n=10, columns='Lift')"
      ],
      "metadata": {
        "id": "d1uOwrq0SWpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">- `def inspect(results)`:This line defines a function named inspect that will extract specific metrics from the results list containing the association rules.\n",
        "- `lhs`: This list comprehension extracts the items in the antecedent (the left side of the rule) for each result.\n",
        "- `rhs`: This list comprehension extracts the items in the consequent (the right side of the rule) for each result.\n",
        "\n",
        ">- `supports`: Extracts the support value for each rule.\n",
        "- `confidences`: Extracts the confidence value for each rule.\n",
        "- `lifts`: Extracts the lift value for each rule.\n",
        "\n",
        ">- The  `zip` function combines the extracted lists into tuples, where each tuple represents a rule with its `LHS`, `RHS`, `support`, `confidence`, and `lift`. This is returned as a list of tuples.\n",
        "\n",
        ">- `resultsinDataFrame=[...]`: This line creates a pandas DataFrame named   `resultsinDataFrame` from the inspected results, with specified column names.\n",
        "\n",
        ">- `resultsinDataFrame['Lift']=...` :This ensures that the Lift column is in numeric format, allowing for numerical operations and comparisons.\n",
        "\n",
        ">- `nlargest(n=10, columns='Lift')`: This function retrieves the top 10 rules with the highest lift values, which indicates the strongest associations among items.\n"
      ],
      "metadata": {
        "id": "7JNqZDG_zFC7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mO9Yddm4TYlb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}